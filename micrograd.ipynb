{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/zirklelc/micrograd?scriptVersionId=157179982\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"markdown","id":"729957c8","metadata":{"papermill":{"duration":0.006387,"end_time":"2023-12-31T07:29:08.053109","exception":false,"start_time":"2023-12-31T07:29:08.046722","status":"completed"},"tags":[]},"source":["###  Titanic with MicroGrad"]},{"cell_type":"code","execution_count":28,"id":"094ef681","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:08.066068Z","iopub.status.busy":"2023-12-31T07:29:08.06556Z","iopub.status.idle":"2023-12-31T07:29:19.453978Z","shell.execute_reply":"2023-12-31T07:29:19.452051Z"},"papermill":{"duration":11.397887,"end_time":"2023-12-31T07:29:19.456465","exception":false,"start_time":"2023-12-31T07:29:08.058578","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: micrograd in ./venv/lib/python3.11/site-packages (0.1.0)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install micrograd"]},{"cell_type":"code","execution_count":29,"id":"1de1c692","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:19.469512Z","iopub.status.busy":"2023-12-31T07:29:19.469131Z","iopub.status.idle":"2023-12-31T07:29:19.794447Z","shell.execute_reply":"2023-12-31T07:29:19.793393Z"},"papermill":{"duration":0.334597,"end_time":"2023-12-31T07:29:19.796973","exception":false,"start_time":"2023-12-31T07:29:19.462376","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from micrograd.engine import Value\n","from micrograd.nn import MLP\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":30,"id":"a3ecff59","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:19.810589Z","iopub.status.busy":"2023-12-31T07:29:19.81007Z","iopub.status.idle":"2023-12-31T07:29:19.868815Z","shell.execute_reply":"2023-12-31T07:29:19.867749Z"},"papermill":{"duration":0.068438,"end_time":"2023-12-31T07:29:19.871625","exception":false,"start_time":"2023-12-31T07:29:19.803187","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Survived  Pclass  \\\n","PassengerId                     \n","1                   0       3   \n","2                   1       1   \n","3                   1       3   \n","4                   1       1   \n","5                   0       3   \n","\n","                                                          Name     Sex   Age  \\\n","PassengerId                                                                    \n","1                                      Braund, Mr. Owen Harris    male  22.0   \n","2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n","3                                       Heikkinen, Miss. Laina  female  26.0   \n","4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n","5                                     Allen, Mr. William Henry    male  35.0   \n","\n","             SibSp  Parch            Ticket     Fare Cabin Embarked  \n","PassengerId                                                          \n","1                1      0         A/5 21171   7.2500   NaN        S  \n","2                1      0          PC 17599  71.2833   C85        C  \n","3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n","4                1      0            113803  53.1000  C123        S  \n","5                0      0            373450   8.0500   NaN        S  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Load train and test datasets\n","train_df = pd.read_csv(\"../input/titanic/train.csv\", index_col=\"PassengerId\")\n","test_df = pd.read_csv(\"../input/titanic/test.csv\", index_col=\"PassengerId\")\n","\n","train_df.head(5)"]},{"cell_type":"code","execution_count":31,"id":"9b382bdc","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:19.886243Z","iopub.status.busy":"2023-12-31T07:29:19.884857Z","iopub.status.idle":"2023-12-31T07:29:19.910124Z","shell.execute_reply":"2023-12-31T07:29:19.908914Z"},"papermill":{"duration":0.034613,"end_time":"2023-12-31T07:29:19.912417","exception":false,"start_time":"2023-12-31T07:29:19.877804","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Survived  Pclass  Sex   Age  SibSp  Parch     Fare Embarked\n","PassengerId                                                             \n","1                   0       3    1  22.0      1      0   7.2500        S\n","2                   1       1    0  38.0      1      0  71.2833        C\n","3                   1       3    0  26.0      0      0   7.9250        S\n","4                   1       1    0  35.0      1      0  53.1000        S\n","5                   0       3    1  35.0      0      0   8.0500        S"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# Preprocess datasets\n","datasets = [train_df, test_df]\n","\n","# Calculate the median age and fare from teh training dataset\n","median_age = train_df[\"Age\"].median()\n","median_fare = train_df[\"Fare\"].median()\n","\n","# Iterate over both datasets\n","for dataset in datasets:\n","    # Fill NaNs for `Age` and `Fare` with the columns' median value.\n","    # Note to fill NaNs in the test dataset with the median values from the training dataset.\n","    dataset[\"Age\"].fillna(median_age, inplace=True)\n","    dataset[\"Fare\"].fillna(median_fare, inplace=True)\n","\n","    # Convert `Sex` into categorical feature\n","    dataset[\"Sex\"] = pd.Categorical(dataset[\"Sex\"])\n","    dataset[\"Sex\"] = dataset[\"Sex\"].cat.codes\n","\n","    # Note not to convert `Embarked` into a categorical feature here, because the training set missing values but the test set does not.\n","    # This results in more columns on the training dataset than on the test dataset when converted into categorical features.\n","    # This will be handled by the `get_dummies` function later.\n","    dataset[\"Embarked\"] = dataset[\"Embarked\"]\n","\n","    # Drop columns that are not useful for prediction\n","    dataset.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1, inplace=True)\n","\n","train_df.head(5)"]},{"cell_type":"code","execution_count":32,"id":"e59bd581","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:19.926546Z","iopub.status.busy":"2023-12-31T07:29:19.925567Z","iopub.status.idle":"2023-12-31T07:29:19.9442Z","shell.execute_reply":"2023-12-31T07:29:19.942608Z"},"papermill":{"duration":0.028051,"end_time":"2023-12-31T07:29:19.946569","exception":false,"start_time":"2023-12-31T07:29:19.918518","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 891 entries, 1 to 891\n","Data columns (total 8 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Survived  891 non-null    int64  \n"," 1   Pclass    891 non-null    int64  \n"," 2   Sex       891 non-null    int8   \n"," 3   Age       891 non-null    float64\n"," 4   SibSp     891 non-null    int64  \n"," 5   Parch     891 non-null    int64  \n"," 6   Fare      891 non-null    float64\n"," 7   Embarked  889 non-null    object \n","dtypes: float64(2), int64(4), int8(1), object(1)\n","memory usage: 56.6+ KB\n"]}],"source":["# Check training dataset for data types\n","train_df.info()"]},{"cell_type":"code","execution_count":33,"id":"7ffc3fb5","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:19.960663Z","iopub.status.busy":"2023-12-31T07:29:19.960224Z","iopub.status.idle":"2023-12-31T07:29:19.973738Z","shell.execute_reply":"2023-12-31T07:29:19.97204Z"},"papermill":{"duration":0.022899,"end_time":"2023-12-31T07:29:19.975712","exception":false,"start_time":"2023-12-31T07:29:19.952813","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 418 entries, 892 to 1309\n","Data columns (total 7 columns):\n"," #   Column    Non-Null Count  Dtype  \n","---  ------    --------------  -----  \n"," 0   Pclass    418 non-null    int64  \n"," 1   Sex       418 non-null    int8   \n"," 2   Age       418 non-null    float64\n"," 3   SibSp     418 non-null    int64  \n"," 4   Parch     418 non-null    int64  \n"," 5   Fare      418 non-null    float64\n"," 6   Embarked  418 non-null    object \n","dtypes: float64(2), int64(3), int8(1), object(1)\n","memory usage: 23.3+ KB\n"]}],"source":["# Check test dataset for data types\n","test_df.info()"]},{"cell_type":"code","execution_count":34,"id":"db084ac2","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:19.991553Z","iopub.status.busy":"2023-12-31T07:29:19.991077Z","iopub.status.idle":"2023-12-31T07:29:20.013061Z","shell.execute_reply":"2023-12-31T07:29:20.011884Z"},"papermill":{"duration":0.03323,"end_time":"2023-12-31T07:29:20.015487","exception":false,"start_time":"2023-12-31T07:29:19.982257","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the columns for one-hot encoding\n","categorical_cols = [\"Pclass\", \"Sex\", \"Embarked\", \"SibSp\"]\n","\n","# Convert categorical variable into dummy/indicator variables.\n","# Note to use the `dummy_na=True` parameter to create a column for unknown values\n","# https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\n","train_dummies_df = pd.get_dummies(\n","    train_df,\n","    columns=categorical_cols,\n","    prefix=categorical_cols,\n","    dummy_na=True,\n","    # dtype=int\n",")\n","test_dummies_df = pd.get_dummies(\n","    test_df,\n","    columns=categorical_cols,\n","    prefix=categorical_cols,\n","    dummy_na=True,\n","    # dtype=int\n",")"]},{"cell_type":"code","execution_count":35,"id":"480158cf","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:20.031384Z","iopub.status.busy":"2023-12-31T07:29:20.030487Z","iopub.status.idle":"2023-12-31T07:29:20.053297Z","shell.execute_reply":"2023-12-31T07:29:20.052432Z"},"papermill":{"duration":0.033459,"end_time":"2023-12-31T07:29:20.055399","exception":false,"start_time":"2023-12-31T07:29:20.02194","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Age</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Pclass_1.0</th>\n","      <th>Pclass_2.0</th>\n","      <th>Pclass_3.0</th>\n","      <th>Pclass_nan</th>\n","      <th>Sex_0.0</th>\n","      <th>Sex_1.0</th>\n","      <th>...</th>\n","      <th>Embarked_S</th>\n","      <th>Embarked_nan</th>\n","      <th>SibSp_0.0</th>\n","      <th>SibSp_1.0</th>\n","      <th>SibSp_2.0</th>\n","      <th>SibSp_3.0</th>\n","      <th>SibSp_4.0</th>\n","      <th>SibSp_5.0</th>\n","      <th>SibSp_8.0</th>\n","      <th>SibSp_nan</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>38.0</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["             Survived   Age  Parch     Fare  Pclass_1.0  Pclass_2.0  \\\n","PassengerId                                                           \n","1                   0  22.0      0   7.2500       False       False   \n","2                   1  38.0      0  71.2833        True       False   \n","3                   1  26.0      0   7.9250       False       False   \n","4                   1  35.0      0  53.1000        True       False   \n","5                   0  35.0      0   8.0500       False       False   \n","\n","             Pclass_3.0  Pclass_nan  Sex_0.0  Sex_1.0  ...  Embarked_S  \\\n","PassengerId                                            ...               \n","1                  True       False    False     True  ...        True   \n","2                 False       False     True    False  ...       False   \n","3                  True       False     True    False  ...        True   \n","4                 False       False     True    False  ...        True   \n","5                  True       False    False     True  ...        True   \n","\n","             Embarked_nan  SibSp_0.0  SibSp_1.0  SibSp_2.0  SibSp_3.0  \\\n","PassengerId                                                             \n","1                   False      False       True      False      False   \n","2                   False      False       True      False      False   \n","3                   False       True      False      False      False   \n","4                   False      False       True      False      False   \n","5                   False       True      False      False      False   \n","\n","             SibSp_4.0  SibSp_5.0  SibSp_8.0  SibSp_nan  \n","PassengerId                                              \n","1                False      False      False      False  \n","2                False      False      False      False  \n","3                False      False      False      False  \n","4                False      False      False      False  \n","5                False      False      False      False  \n","\n","[5 rows x 23 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["train_dummies_df.head(5)"]},{"cell_type":"code","execution_count":36,"id":"938b4f24","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:20.07014Z","iopub.status.busy":"2023-12-31T07:29:20.069826Z","iopub.status.idle":"2023-12-31T07:29:20.089585Z","shell.execute_reply":"2023-12-31T07:29:20.088708Z"},"papermill":{"duration":0.028976,"end_time":"2023-12-31T07:29:20.091208","exception":false,"start_time":"2023-12-31T07:29:20.062232","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Pclass_1.0</th>\n","      <th>Pclass_2.0</th>\n","      <th>Pclass_3.0</th>\n","      <th>Pclass_nan</th>\n","      <th>Sex_0.0</th>\n","      <th>Sex_1.0</th>\n","      <th>Sex_nan</th>\n","      <th>...</th>\n","      <th>Embarked_S</th>\n","      <th>Embarked_nan</th>\n","      <th>SibSp_0.0</th>\n","      <th>SibSp_1.0</th>\n","      <th>SibSp_2.0</th>\n","      <th>SibSp_3.0</th>\n","      <th>SibSp_4.0</th>\n","      <th>SibSp_5.0</th>\n","      <th>SibSp_8.0</th>\n","      <th>SibSp_nan</th>\n","    </tr>\n","    <tr>\n","      <th>PassengerId</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>892</th>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>7.8292</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>893</th>\n","      <td>47.0</td>\n","      <td>0</td>\n","      <td>7.0000</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>894</th>\n","      <td>62.0</td>\n","      <td>0</td>\n","      <td>9.6875</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>895</th>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>8.6625</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>896</th>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>12.2875</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>...</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>"],"text/plain":["              Age  Parch     Fare  Pclass_1.0  Pclass_2.0  Pclass_3.0  \\\n","PassengerId                                                             \n","892          34.5      0   7.8292       False       False        True   \n","893          47.0      0   7.0000       False       False        True   \n","894          62.0      0   9.6875       False        True       False   \n","895          27.0      0   8.6625       False       False        True   \n","896          22.0      1  12.2875       False       False        True   \n","\n","             Pclass_nan  Sex_0.0  Sex_1.0  Sex_nan  ...  Embarked_S  \\\n","PassengerId                                         ...               \n","892               False    False     True    False  ...       False   \n","893               False     True    False    False  ...        True   \n","894               False    False     True    False  ...       False   \n","895               False    False     True    False  ...        True   \n","896               False     True    False    False  ...        True   \n","\n","             Embarked_nan  SibSp_0.0  SibSp_1.0  SibSp_2.0  SibSp_3.0  \\\n","PassengerId                                                             \n","892                 False       True      False      False      False   \n","893                 False      False       True      False      False   \n","894                 False       True      False      False      False   \n","895                 False       True      False      False      False   \n","896                 False      False       True      False      False   \n","\n","             SibSp_4.0  SibSp_5.0  SibSp_8.0  SibSp_nan  \n","PassengerId                                              \n","892              False      False      False      False  \n","893              False      False      False      False  \n","894              False      False      False      False  \n","895              False      False      False      False  \n","896              False      False      False      False  \n","\n","[5 rows x 22 columns]"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["test_dummies_df.head(5)"]},{"cell_type":"code","execution_count":37,"id":"5452613b","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:20.107961Z","iopub.status.busy":"2023-12-31T07:29:20.106636Z","iopub.status.idle":"2023-12-31T07:29:20.11469Z","shell.execute_reply":"2023-12-31T07:29:20.113169Z"},"papermill":{"duration":0.018321,"end_time":"2023-12-31T07:29:20.116589","exception":false,"start_time":"2023-12-31T07:29:20.098268","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["train_dummies_df.shape: (891, 23)\n","test_dummies_df.shape: (418, 22)\n"]}],"source":["# Check if train and test dataset have the same number of columns\n","# Note `Survived` is not included in test data set, so we exclude it from the comparison\n","assert train_dummies_df.iloc[:, 1:].columns.equals(\n","    test_dummies_df.columns\n","), \"train_dummies_df and test_dummies_df do not have the same columns\"\n","\n","print(f\"train_dummies_df.shape: {train_dummies_df.shape}\")\n","print(f\"test_dummies_df.shape: {test_dummies_df.shape}\")"]},{"cell_type":"code","execution_count":38,"id":"12931101","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:20.131366Z","iopub.status.busy":"2023-12-31T07:29:20.131026Z","iopub.status.idle":"2023-12-31T07:29:20.13875Z","shell.execute_reply":"2023-12-31T07:29:20.137315Z"},"papermill":{"duration":0.017346,"end_time":"2023-12-31T07:29:20.140871","exception":false,"start_time":"2023-12-31T07:29:20.123525","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Survival rate: 38.38%\n"]}],"source":["# Calculate survival rate\n","total_samples = train_dummies_df.shape[0]  # Total number of samples\n","num_survived = (train_dummies_df[\"Survived\"] == 1).sum()  # Number of survivors\n","rate_survival = (num_survived / total_samples) * 100\n","\n","print(f\"Survival rate: {rate_survival:.2f}%\")"]},{"cell_type":"code","execution_count":39,"id":"6c466336","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:20.156618Z","iopub.status.busy":"2023-12-31T07:29:20.156223Z","iopub.status.idle":"2023-12-31T07:29:21.241694Z","shell.execute_reply":"2023-12-31T07:29:21.240698Z"},"papermill":{"duration":1.096055,"end_time":"2023-12-31T07:29:21.243894","exception":false,"start_time":"2023-12-31T07:29:20.147839","status":"completed"},"tags":[]},"outputs":[],"source":["# Standardize datasets\n","from sklearn.preprocessing import StandardScaler\n","\n","# Use standard scaling with mean and standard deviation from the training dataset\n","# Note to use the same scaler for both training and test datasets\n","# The `Survived` column is excluded from the scaling by using `iloc[:, 1:]`\n","# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n","scaler = StandardScaler()\n","scaler.fit(train_dummies_df.iloc[:, 1:])\n","train_scaled = scaler.transform(train_dummies_df.iloc[:, 1:])\n","test_scaled = scaler.transform(test_dummies_df)\n","\n","train_scaled_df = pd.DataFrame(\n","    train_scaled,\n","    index=train_dummies_df.index,\n","    columns=train_dummies_df.iloc[:, 1:].columns,\n",")\n","\n","test_scaled_df = pd.DataFrame(\n","    test_scaled, index=test_dummies_df.index, columns=test_dummies_df.columns\n",")"]},{"cell_type":"code","execution_count":40,"id":"78151910","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.259502Z","iopub.status.busy":"2023-12-31T07:29:21.258942Z","iopub.status.idle":"2023-12-31T07:29:21.284061Z","shell.execute_reply":"2023-12-31T07:29:21.282859Z"},"papermill":{"duration":0.035637,"end_time":"2023-12-31T07:29:21.286619","exception":false,"start_time":"2023-12-31T07:29:21.250982","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Age</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.383838</td>\n","      <td>29.361582</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.486592</td>\n","      <td>13.019697</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>35.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>80.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Survived         Age       Parch        Fare\n","count  891.000000  891.000000  891.000000  891.000000\n","mean     0.383838   29.361582    0.381594   32.204208\n","std      0.486592   13.019697    0.806057   49.693429\n","min      0.000000    0.420000    0.000000    0.000000\n","25%      0.000000   22.000000    0.000000    7.910400\n","50%      0.000000   28.000000    0.000000   14.454200\n","75%      1.000000   35.000000    0.000000   31.000000\n","max      1.000000   80.000000    6.000000  512.329200"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["train_dummies_df.describe()"]},{"cell_type":"code","execution_count":41,"id":"0fd45d0b","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.303523Z","iopub.status.busy":"2023-12-31T07:29:21.303208Z","iopub.status.idle":"2023-12-31T07:29:21.368677Z","shell.execute_reply":"2023-12-31T07:29:21.367347Z"},"papermill":{"duration":0.07667,"end_time":"2023-12-31T07:29:21.370642","exception":false,"start_time":"2023-12-31T07:29:21.293972","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Pclass_1.0</th>\n","      <th>Pclass_2.0</th>\n","      <th>Pclass_3.0</th>\n","      <th>Pclass_nan</th>\n","      <th>Sex_0.0</th>\n","      <th>Sex_1.0</th>\n","      <th>Sex_nan</th>\n","      <th>...</th>\n","      <th>Embarked_S</th>\n","      <th>Embarked_nan</th>\n","      <th>SibSp_0.0</th>\n","      <th>SibSp_1.0</th>\n","      <th>SibSp_2.0</th>\n","      <th>SibSp_3.0</th>\n","      <th>SibSp_4.0</th>\n","      <th>SibSp_5.0</th>\n","      <th>SibSp_8.0</th>\n","      <th>SibSp_nan</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>891.0</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>891.0</td>\n","      <td>...</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>8.910000e+02</td>\n","      <td>891.0</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.272780e-16</td>\n","      <td>5.382900e-17</td>\n","      <td>3.987333e-18</td>\n","      <td>-7.575933e-17</td>\n","      <td>1.993666e-17</td>\n","      <td>-6.778466e-17</td>\n","      <td>0.0</td>\n","      <td>3.987333e-17</td>\n","      <td>-1.156327e-16</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>-4.984166e-17</td>\n","      <td>3.189866e-17</td>\n","      <td>-4.386066e-17</td>\n","      <td>4.984166e-18</td>\n","      <td>2.292716e-17</td>\n","      <td>-6.778466e-17</td>\n","      <td>-7.177199e-17</td>\n","      <td>1.395567e-17</td>\n","      <td>-1.196200e-17</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>0.0</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>1.000562e+00</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>-2.224156e+00</td>\n","      <td>-4.736736e-01</td>\n","      <td>-6.484217e-01</td>\n","      <td>-5.656854e-01</td>\n","      <td>-5.101515e-01</td>\n","      <td>-1.107926e+00</td>\n","      <td>0.0</td>\n","      <td>-7.376951e-01</td>\n","      <td>-1.355574e+00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>-1.614710e+00</td>\n","      <td>-4.743120e-02</td>\n","      <td>-1.465746e+00</td>\n","      <td>-5.535807e-01</td>\n","      <td>-1.801248e-01</td>\n","      <td>-1.352247e-01</td>\n","      <td>-1.435916e-01</td>\n","      <td>-7.512217e-02</td>\n","      <td>-8.898625e-02</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>-5.657365e-01</td>\n","      <td>-4.736736e-01</td>\n","      <td>-4.891482e-01</td>\n","      <td>-5.656854e-01</td>\n","      <td>-5.101515e-01</td>\n","      <td>-1.107926e+00</td>\n","      <td>0.0</td>\n","      <td>-7.376951e-01</td>\n","      <td>-1.355574e+00</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>-1.614710e+00</td>\n","      <td>-4.743120e-02</td>\n","      <td>-1.465746e+00</td>\n","      <td>-5.535807e-01</td>\n","      <td>-1.801248e-01</td>\n","      <td>-1.352247e-01</td>\n","      <td>-1.435916e-01</td>\n","      <td>-7.512217e-02</td>\n","      <td>-8.898625e-02</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>-1.046374e-01</td>\n","      <td>-4.736736e-01</td>\n","      <td>-3.573909e-01</td>\n","      <td>-5.656854e-01</td>\n","      <td>-5.101515e-01</td>\n","      <td>9.025874e-01</td>\n","      <td>0.0</td>\n","      <td>-7.376951e-01</td>\n","      <td>7.376951e-01</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>6.193064e-01</td>\n","      <td>-4.743120e-02</td>\n","      <td>6.822467e-01</td>\n","      <td>-5.535807e-01</td>\n","      <td>-1.801248e-01</td>\n","      <td>-1.352247e-01</td>\n","      <td>-1.435916e-01</td>\n","      <td>-7.512217e-02</td>\n","      <td>-8.898625e-02</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>4.333115e-01</td>\n","      <td>-4.736736e-01</td>\n","      <td>-2.424635e-02</td>\n","      <td>-5.656854e-01</td>\n","      <td>-5.101515e-01</td>\n","      <td>9.025874e-01</td>\n","      <td>0.0</td>\n","      <td>1.355574e+00</td>\n","      <td>7.376951e-01</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>6.193064e-01</td>\n","      <td>-4.743120e-02</td>\n","      <td>6.822467e-01</td>\n","      <td>-5.535807e-01</td>\n","      <td>-1.801248e-01</td>\n","      <td>-1.352247e-01</td>\n","      <td>-1.435916e-01</td>\n","      <td>-7.512217e-02</td>\n","      <td>-8.898625e-02</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.891554e+00</td>\n","      <td>6.974147e+00</td>\n","      <td>9.667167e+00</td>\n","      <td>1.767767e+00</td>\n","      <td>1.960202e+00</td>\n","      <td>9.025874e-01</td>\n","      <td>0.0</td>\n","      <td>1.355574e+00</td>\n","      <td>7.376951e-01</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>6.193064e-01</td>\n","      <td>2.108317e+01</td>\n","      <td>6.822467e-01</td>\n","      <td>1.806421e+00</td>\n","      <td>5.551705e+00</td>\n","      <td>7.395100e+00</td>\n","      <td>6.964194e+00</td>\n","      <td>1.331165e+01</td>\n","      <td>1.123769e+01</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 22 columns</p>\n","</div>"],"text/plain":["                Age         Parch          Fare    Pclass_1.0    Pclass_2.0  \\\n","count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02   \n","mean   2.272780e-16  5.382900e-17  3.987333e-18 -7.575933e-17  1.993666e-17   \n","std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00   \n","min   -2.224156e+00 -4.736736e-01 -6.484217e-01 -5.656854e-01 -5.101515e-01   \n","25%   -5.657365e-01 -4.736736e-01 -4.891482e-01 -5.656854e-01 -5.101515e-01   \n","50%   -1.046374e-01 -4.736736e-01 -3.573909e-01 -5.656854e-01 -5.101515e-01   \n","75%    4.333115e-01 -4.736736e-01 -2.424635e-02 -5.656854e-01 -5.101515e-01   \n","max    3.891554e+00  6.974147e+00  9.667167e+00  1.767767e+00  1.960202e+00   \n","\n","         Pclass_3.0  Pclass_nan       Sex_0.0       Sex_1.0  Sex_nan  ...  \\\n","count  8.910000e+02       891.0  8.910000e+02  8.910000e+02    891.0  ...   \n","mean  -6.778466e-17         0.0  3.987333e-17 -1.156327e-16      0.0  ...   \n","std    1.000562e+00         0.0  1.000562e+00  1.000562e+00      0.0  ...   \n","min   -1.107926e+00         0.0 -7.376951e-01 -1.355574e+00      0.0  ...   \n","25%   -1.107926e+00         0.0 -7.376951e-01 -1.355574e+00      0.0  ...   \n","50%    9.025874e-01         0.0 -7.376951e-01  7.376951e-01      0.0  ...   \n","75%    9.025874e-01         0.0  1.355574e+00  7.376951e-01      0.0  ...   \n","max    9.025874e-01         0.0  1.355574e+00  7.376951e-01      0.0  ...   \n","\n","         Embarked_S  Embarked_nan     SibSp_0.0     SibSp_1.0     SibSp_2.0  \\\n","count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02   \n","mean  -4.984166e-17  3.189866e-17 -4.386066e-17  4.984166e-18  2.292716e-17   \n","std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00   \n","min   -1.614710e+00 -4.743120e-02 -1.465746e+00 -5.535807e-01 -1.801248e-01   \n","25%   -1.614710e+00 -4.743120e-02 -1.465746e+00 -5.535807e-01 -1.801248e-01   \n","50%    6.193064e-01 -4.743120e-02  6.822467e-01 -5.535807e-01 -1.801248e-01   \n","75%    6.193064e-01 -4.743120e-02  6.822467e-01 -5.535807e-01 -1.801248e-01   \n","max    6.193064e-01  2.108317e+01  6.822467e-01  1.806421e+00  5.551705e+00   \n","\n","          SibSp_3.0     SibSp_4.0     SibSp_5.0     SibSp_8.0  SibSp_nan  \n","count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02      891.0  \n","mean  -6.778466e-17 -7.177199e-17  1.395567e-17 -1.196200e-17        0.0  \n","std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00        0.0  \n","min   -1.352247e-01 -1.435916e-01 -7.512217e-02 -8.898625e-02        0.0  \n","25%   -1.352247e-01 -1.435916e-01 -7.512217e-02 -8.898625e-02        0.0  \n","50%   -1.352247e-01 -1.435916e-01 -7.512217e-02 -8.898625e-02        0.0  \n","75%   -1.352247e-01 -1.435916e-01 -7.512217e-02 -8.898625e-02        0.0  \n","max    7.395100e+00  6.964194e+00  1.331165e+01  1.123769e+01        0.0  \n","\n","[8 rows x 22 columns]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["train_scaled_df.describe()"]},{"cell_type":"code","execution_count":42,"id":"2f2fc7b2","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.386719Z","iopub.status.busy":"2023-12-31T07:29:21.386396Z","iopub.status.idle":"2023-12-31T07:29:21.391932Z","shell.execute_reply":"2023-12-31T07:29:21.390624Z"},"papermill":{"duration":0.01582,"end_time":"2023-12-31T07:29:21.393759","exception":false,"start_time":"2023-12-31T07:29:21.377939","status":"completed"},"tags":[]},"outputs":[],"source":["# Check train and test datasets have the same columns\n","# Note `Surivived` was removed during scaling\n","assert train_scaled_df.columns.equals(\n","    test_scaled_df.columns\n","), \"train_scaled_df and test_scaled_df do not have the same columns\""]},{"cell_type":"code","execution_count":43,"id":"5115eca4","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.409678Z","iopub.status.busy":"2023-12-31T07:29:21.409424Z","iopub.status.idle":"2023-12-31T07:29:21.523372Z","shell.execute_reply":"2023-12-31T07:29:21.521963Z"},"papermill":{"duration":0.126603,"end_time":"2023-12-31T07:29:21.527793","exception":false,"start_time":"2023-12-31T07:29:21.40119","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["training dataset: (801, 22)\n","validation dataset: (90, 22)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Take target labels from the unscaled training dataset and input features from the scaled training dataset\n","train_labels = train_dummies_df[\"Survived\"].to_numpy()\n","train_features = train_scaled_df.to_numpy()\n","\n","# Split the training dataset into training and validation datasets\n","# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","X_train, X_validate, y_train, y_validate = train_test_split(\n","    train_features, train_labels, test_size=0.1\n",")\n","\n","print(f\"training dataset: {X_train.shape}\")\n","print(f\"validation dataset: {X_validate.shape}\")"]},{"cell_type":"code","execution_count":44,"id":"757a1360","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.545679Z","iopub.status.busy":"2023-12-31T07:29:21.545019Z","iopub.status.idle":"2023-12-31T07:29:21.549197Z","shell.execute_reply":"2023-12-31T07:29:21.548555Z"},"papermill":{"duration":0.015911,"end_time":"2023-12-31T07:29:21.551768","exception":false,"start_time":"2023-12-31T07:29:21.535857","status":"completed"},"tags":[]},"outputs":[],"source":["def init_model(n_input, n_hidden=[], n_output=1):\n","    nodes = n_hidden + [n_output]\n","\n","    model = MLP(n_input, nodes)\n","    return model"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["import math\n","\n","# Micograd doesn't have a sigmoid function\n","def sigmoid(value):\n","\tx = value.data\n","\te = math.exp(x)\n","\tt = (e) / (e + 1)\n","\tout = Value(t, (value,), \"Sigmoid\")\n","\n","\tdef _backward():\n","\t\t\tvalue.grad += (e) / ((1 + e) ** 2) * out.grad\n","\n","\tout._backward = _backward\n","\n","\treturn out"]},{"cell_type":"code","execution_count":46,"id":"913034fc","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.570215Z","iopub.status.busy":"2023-12-31T07:29:21.569584Z","iopub.status.idle":"2023-12-31T07:29:21.574814Z","shell.execute_reply":"2023-12-31T07:29:21.573707Z"},"papermill":{"duration":0.015908,"end_time":"2023-12-31T07:29:21.57653","exception":false,"start_time":"2023-12-31T07:29:21.560622","status":"completed"},"tags":[]},"outputs":[],"source":["def forward(model, features):\n","    # assert features is 2d numpy array\n","    assert len(features.shape) == 2\n","\n","    # map features to micrograd values\n","    inputs = [list(map(Value, row)) for row in features]\n","\n","    # forward the model to get predictions\n","    predictions = list(map(model, inputs))\n","\n","    # apply sigmoid to predictions\n","    predictions = list(map(sigmoid, predictions))\n","\n","    return np.asarray(predictions)"]},{"cell_type":"code","execution_count":47,"id":"611a6abf","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.597107Z","iopub.status.busy":"2023-12-31T07:29:21.596459Z","iopub.status.idle":"2023-12-31T07:29:21.603256Z","shell.execute_reply":"2023-12-31T07:29:21.602191Z"},"papermill":{"duration":0.021531,"end_time":"2023-12-31T07:29:21.605338","exception":false,"start_time":"2023-12-31T07:29:21.583807","status":"completed"},"tags":[]},"outputs":[],"source":["def loss(predictions, labels):\n","    # assert predictions and labels are 1d numpy arrays\n","    assert len(predictions.shape) == 1, \"predictions must be 1d numpy array\"\n","    assert len(labels.shape) == 1, \"labels must be 1d numpy array\"\n","    assert len(predictions) == len(\n","        labels\n","    ), \"predictions and labels must have the same length\"\n","\n","    # svm \"max-margin\" loss\n","    # losses = [(1 + -label*prediction).relu() for label, prediction in zip(labels, predictions)]\n","    # data_loss = sum(losses) * (1.0 / len(losses))\n","\n","    # L2 regularization\n","    # alpha = 1e-4\n","    # reg_loss = alpha * sum((p*p for p in model.parameters()))\n","    # total_loss = data_loss + reg_loss\n","    # return total_loss\n","    \n","    # mean squared error loss\n","    losses = [\n","        (prediction - label) ** 2 for label, prediction in zip(labels, predictions)\n","    ]\n","    total_loss = sum(losses) * (1.0 / len(losses))\n","    return total_loss\n"]},{"cell_type":"code","execution_count":48,"id":"4d9c32d4","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.624896Z","iopub.status.busy":"2023-12-31T07:29:21.624245Z","iopub.status.idle":"2023-12-31T07:29:21.630354Z","shell.execute_reply":"2023-12-31T07:29:21.629465Z"},"papermill":{"duration":0.019647,"end_time":"2023-12-31T07:29:21.63372","exception":false,"start_time":"2023-12-31T07:29:21.614073","status":"completed"},"tags":[]},"outputs":[],"source":["def accuracy(predictions, labels):\n","    # assert predictions and labels are 1d numpy arrays\n","    assert len(predictions.shape) == 1, \"predictions must be 1d numpy array\"\n","    assert len(labels.shape) == 1, \"labels must be 1d numpy array\"\n","    assert len(predictions) == len(\n","            labels\n","    ), \"predictions and labels must have the same length\"\n","\n","    # Extract values from micrograd Value objects\n","    predicted_values = np.array([value.data for value in predictions])\n","\n","    # Convert predictions to binary values (0 or 1) based on the threshold\n","    binary_predictions = (predicted_values > 0.5).astype(int)\n","\n","    # Compare binary_predictions with true_labels\n","    correct_predictions = np.sum(binary_predictions == labels)\n","\n","    # Calculate accuracy\n","    accuracy = correct_predictions / len(labels)\n","\n","    return accuracy"]},{"cell_type":"code","execution_count":49,"id":"8803467e","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.652116Z","iopub.status.busy":"2023-12-31T07:29:21.651467Z","iopub.status.idle":"2023-12-31T07:29:21.656741Z","shell.execute_reply":"2023-12-31T07:29:21.6562Z"},"papermill":{"duration":0.016073,"end_time":"2023-12-31T07:29:21.658433","exception":false,"start_time":"2023-12-31T07:29:21.64236","status":"completed"},"tags":[]},"outputs":[],"source":["def optimize(model, epoch, loss):\n","    # unpack epochs\n","    epoch, num_epochs = epoch\n","    \n","    model.zero_grad()\n","    loss.backward()\n","\n","    # learning_rate = 1.0-0.9*k/100\n","    # learning_rate = 0.001\n","    start_lr = 0.01\n","    end_lr = 0.001\n","    learning_rate = max(\n","        (start_lr - (start_lr - end_lr) * epoch / (num_epochs - 1)), \n","        end_lr\n","    )\n","    for p in model.parameters():\n","        p.data -= learning_rate * p.grad"]},{"cell_type":"code","execution_count":50,"id":"db3e4d89","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.674921Z","iopub.status.busy":"2023-12-31T07:29:21.674351Z","iopub.status.idle":"2023-12-31T07:29:21.797062Z","shell.execute_reply":"2023-12-31T07:29:21.796122Z"},"papermill":{"duration":0.134077,"end_time":"2023-12-31T07:29:21.79977","exception":false,"start_time":"2023-12-31T07:29:21.665693","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.utils import shuffle\n","\n","\n","def train_model(model, xy_train, xy_validate, num_epochs=100, batch_size=32):\n","    # Unpack training and validation data\n","    x_train, y_train = xy_train\n","    x_validate, y_validate = xy_validate\n","\n","    # Calculate number of batches\n","    num_batches = x_train.shape[0] // batch_size\n","\n","    # Losses per epoch\n","    train_losses = [0] * num_epochs\n","    validate_losses = [0] * num_epochs\n","    validate_accuracy = [0] * num_epochs\n","\n","    print(f\"Training on {x_train.shape[0]} samples\")\n","    print(f\"Epochs: {num_epochs}\")\n","    print(f\"Batches: {num_batches} with size {batch_size}\")\n","\n","    for epoch in range(num_epochs):\n","        # Shuffle training data at the beginning of each epoch\n","        x_train, y_train = shuffle(x_train, y_train)\n","\n","        for batch in range(num_batches):\n","            # Calculate next batch indices\n","            start = batch * batch_size\n","            end = start + batch_size\n","            x_batch, y_batch = x_train[start:end], y_train[start:end]\n","\n","            # sample a random batch from the training data\n","            #ri = np.random.permutation(x_train.shape[0])[:batch_size]\n","            #x_batch, y_batch = x_train[ri], y_train[ri]\n","\n","            # train on batch\n","            train_output = forward(model, x_batch)\n","            train_loss = loss(train_output, y_batch)\n","\n","            # optimize after each batch\n","            optimize(model, (epoch, num_epochs), train_loss)\n","\n","        # forward full training set\n","        train_output = forward(model, x_train)\n","        train_loss = loss(train_output, y_train)\n","        train_losses[epoch] = train_loss.data\n","\n","        # forward full validation set\n","        validate_output = forward(model, x_validate)\n","        validate_loss = loss(validate_output, y_validate)\n","        validate_losses[epoch] = validate_loss.data\n","        \n","        # calculate accuracy\n","        validate_accuracy[epoch] = accuracy(validate_output, y_validate)\n","\n","        print(\n","            f\"Epoch {epoch}, train loss {train_loss.data:.3f}, validate loss {validate_loss.data:.3f}, accuracy {(validate_accuracy[epoch]*100):.3f}\"\n","        )\n","\n","    print(\"Training completed.\")\n","    print(f\"Training loss: {train_losses[-1]:.3f}\")\n","    print(f\"Validation loss: {validate_losses[-1]:.3f}\")\n","    print(f\"Validation accuracy: {(validate_accuracy[-1]*100):.3f}%\")\n","\n","    return train_losses, validate_losses, validate_accuracy"]},{"cell_type":"code","execution_count":51,"id":"5a8b9039","metadata":{"execution":{"iopub.execute_input":"2023-12-31T07:29:21.818371Z","iopub.status.busy":"2023-12-31T07:29:21.817689Z","iopub.status.idle":"2023-12-31T09:18:57.85419Z","shell.execute_reply":"2023-12-31T09:18:57.852997Z"},"papermill":{"duration":6576.048928,"end_time":"2023-12-31T09:18:57.857026","exception":false,"start_time":"2023-12-31T07:29:21.808098","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["MLP of [Layer of [ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22), ReLUNeuron(22)], Layer of [ReLUNeuron(15), ReLUNeuron(15), ReLUNeuron(15), ReLUNeuron(15), ReLUNeuron(15), ReLUNeuron(15), ReLUNeuron(15), ReLUNeuron(15)], Layer of [LinearNeuron(8)]]\n","Parameters: 482\n","Training on 801 samples\n","Epochs: 5\n","Batches: 8 with size 100\n","Epoch 0, train loss 0.356, validate loss 0.386, accuracy 47.778\n","Epoch 1, train loss 0.354, validate loss 0.384, accuracy 47.778\n"]}],"source":["# Define number of input features, hidden layers, and output features\n","num_inputs = X_train.shape[1]\n","num_hidden = [15,8]\n","num_outputs = 1\n","\n","# Initialize the model\n","model = init_model(num_inputs, num_hidden, num_outputs)\n","\n","print(model)\n","print(f\"Parameters: {len(model.parameters())}\")\n","\n","# Define the training parameters\n","batch_size = 100\n","num_epochs = 5\n","\n","# Train the model\n","train_losses, validate_losses, validate_accuracy = train_model(\n","    model,\n","    (X_train, y_train),\n","    (X_validate, y_validate),\n","    num_epochs=num_epochs,\n","    batch_size=batch_size,\n",")\n","\n","# Plot the results\n","plt.subplot(211)\n","plt.ylabel('Accuracy')\n","plt.plot(validate_accuracy, label='Accuracy')\n","\n","plt.subplot(212)\n","plt.ylabel('Loss')\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(validate_losses, label='Validation Loss')\n","plt.legend()\n","plt.xlabel(\"Epoch\")"]},{"cell_type":"code","execution_count":null,"id":"d85363d0","metadata":{"execution":{"iopub.execute_input":"2023-12-31T09:18:57.898335Z","iopub.status.busy":"2023-12-31T09:18:57.89798Z","iopub.status.idle":"2023-12-31T09:19:07.689795Z","shell.execute_reply":"2023-12-31T09:19:07.688622Z"},"papermill":{"duration":9.814381,"end_time":"2023-12-31T09:19:07.691598","exception":false,"start_time":"2023-12-31T09:18:57.877217","status":"completed"},"tags":[]},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3.10' requires the ipykernel package.\n","\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n","\u001b[1;31mCommand: '/opt/homebrew/bin/python3.10 -m pip install ipykernel -U --user --force-reinstall'"]}],"source":["# Input features from the scaled test dataset\n","test_features = test_scaled_df.to_numpy()\n","\n","# Forward full test set\n","test_output = forward(model, test_features)\n","test_output_binary = [1 if x.data > 0.5 else 0 for x in test_output]\n","\n","# Create submission dataframe\n","submission_df = pd.DataFrame(test_output_binary, index=test_df.index, columns=[\"Survived\"])\n","submission_df.to_csv(\"submission.csv\")\n","\n","submission_df.head(10)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"papermill":{"default_parameters":{},"duration":6604.855873,"end_time":"2023-12-31T09:19:10.346775","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-12-31T07:29:05.490902","version":"2.4.0"}},"nbformat":4,"nbformat_minor":5}
