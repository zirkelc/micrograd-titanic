# Titanic with Micrograd
This notebook uses Andrej Karpathy's [Micrograd](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbkJGdDA2Y3JzZHlPc0lIOU5DdDVMRTc5cldFQXxBQ3Jtc0trN3ZCRGxaYmtXRWhmUm4wVVZHV2pfdWtuUllIOHl0aFdtSGxTNEpkQ2stY25lY2t6bzIxR2tCWHBGZDNJU3FfTk0xcWFQN0dMZGw2TU1UNE9VWXlvY1pBMmZjR0VYZkJYd1ppWTZlN3UzWURNdlZkSQ&q=https%3A%2F%2Fgithub.com%2Fkarpathy%2Fmicrograd&v=VMj-3S1tku0) library to solve the [Titanic challenge](https://www.kaggle.com/competitions/titanic) on Kaggle. I recommend you watch his phenomenal YouTube video on [building micrograd](https://www.youtube.com/watch?v=VMj-3S1tku0&t=2s&ab_channel=AndrejKarpathy) for an introduction to neural networks and backpropagation. The notebook is available on [Kaggle](https://www.kaggle.com/code/zirklelc/micrograd) in different versions and with different scores. The current best score of [0.76555 (v9)](https://www.kaggle.com/code/zirklelc/micrograd?scriptVersionId=156800490) is very close to other implementations with PyTorch.

## References
Here are some references that helped me with data preparation and implementation:
- https://danielmuellerkomorowska.com/2021/02/03/a-deep-feedforward-network-in-pytorch-for-the-titanic-challenge/
- https://www.kaggle.com/code/jcardenzana/titanic-pytorch
- https://www.kaggle.com/code/kiranscaria/titanic-pytorch
- https://github.com/kurtispykes/Machine-Learning